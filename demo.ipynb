import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import xlrd
import matplotlib.pyplot as plt


# 搭建一个简单的网络， 中间两个隐层
class Net(nn.Module):
    """ 
        in_features   输入的特征数量
        hidden_nodes  隐层的节点数量
        out_features  输出的特征数量
        hidden_nums   隐层的层数
    """
    def __init__(self, in_features, hidden_nodes, out_features,hidden_nums=1):
        super(Net,self).__init__()
        self.fc1 = nn.Linear(in_features, hidden_nodes)   # 输入特征in_features个， 隐层节点数量a个
        self.fc1.weight.data.normal_(0, 0.1)
        self.hidden = []
        for i in range(hidden_nums-1):
            self.hidden.append(nn.Linear(hidden_nodes, hidden_nodes))
            self.hidden[i].weight.data.normal_(0,0.1)
        self.out = nn.Linear(hidden_nodes,out_features)   # 隐层节点数量a个， 输出节点数量out_features
        self.out.weight.data.normal_(0, 0.1)   # 初始化随机权重

    # forward 是训练的过程
    def forward(self,x):                        # 这同时也是 Module 中的 forward 功能
        x = self.fc1(x)                         # 第一层网络的输出值
        x = F.sigmoid(x)                           # 对应调用的激励函数
        for i in range(len(self.hidden)):
            x = self.hidden[i](x)               # 隐层网络的输出值
            x = F.sigmoid(x)   
        value = self.out(x)                     # 最终输出的特征值
        return value



# 训练一个简单地网络
class training():

    def __init__(self,x,y,hidden_nodes=50,hidden_nums=1,):
        # 构建输入集
        in_features = len(x[0])
        out_features = len(y[0])
        print("in_features:",in_features,"   out_features:",out_features)

        self.x = torch.tensor(x).float()
        self.y = torch.tensor(y).float()

        # 输入特征数量  隐层节点数量  输出特征数量  隐层的层数
        self.myNet = Net(in_features,hidden_nodes,out_features,hidden_nums)
        self.Loss = []

    # 固定迭代次数训练过程
    def iterTraining(self,train_nums=1000):
        # 优化器   实现随机梯度下降算法  lr (float) – 学习率
        # optimzer = torch.optim.SGD(self.myNet.parameters(),lr=0.05)        # torch 梯度下降优化器
        optimzer = torch.optim.Adam(self.myNet.parameters(), lr=0.005)        # torch 的优化器  共轭梯度下降优化
        # 损失函数
        loss_func = nn.MSELoss()
        #训练网络
        for epoch in range(train_nums):
            out = self.myNet(self.x)
            loss = loss_func(out, self.y)
            self.Loss.append(loss.item())
            print("epoch:",epoch,"    -Loss_function =", loss.item())
            optimzer.zero_grad()         # 梯度下降执行
            loss.backward()
            optimzer.step()

    # 给定损失函数值训练过程
    def lossTraining(self,lossValue=0.005):
        # 优化器   实现随机梯度下降算法  lr (float) – 学习率
        # optimzer = torch.optim.SGD(self.myNet.parameters(),lr=0.05)        # torch 梯度下降优化器
        optimzer = torch.optim.Adam(self.myNet.parameters(), lr=0.005)        # torch 的优化器  共轭梯度下降优化
        # 损失函数
        loss_func = nn.MSELoss()
        #训练网络
        epoch = 0
        while True:
            out = self.myNet(self.x)
            loss = loss_func(out, self.y)
            self.Loss.append(loss.item())
            print("epoch:",epoch,"    -Loss_function =", loss.item())
            optimzer.zero_grad()         # 梯度下降执行
            loss.backward()
            optimzer.step()
            if loss.item() < lossValue:
                break
            epoch += 1

    # 绘制损失函数过程
    def figures(self,):
        fig = plt.figure(figsize=(8,6))
        ax = fig.add_subplot()   
        x = [ i for i in range(len(self.Loss))]
        plt.plot(x, self.Loss, color='r')
        # plt.show()
        plt.savefig("Loss_function.png")

    # 测试集测试过程
    def testNet(self,tx,ty):
        print("\n***************** 测试集测试 ******************* ")
        tx = torch.tensor(tx).float()
        out = self.myNet(tx).data
        for k in range(len(out)):
            print(k," -测试：",ty[k],"  -预测：",out[k])

    def save(self,):
        # 保存
        torch.save(self.myNet, 'net.pkl')  # save entire net
        torch.save(self.myNet.state_dict(), 'net_params.pkl')   # save parameters



# 读取训练集的数据
class samples():
    def __init__(self,path,xName,yName):
        data = xlrd.open_workbook(path)
        samplex = data.sheet_by_name(xName)
        sampley = data.sheet_by_name(yName)
        self.sapx = []
        self.sapy = []
        for i in range(1,samplex.nrows):
            x = [ samplex.cell(i,j).value for j in range(samplex.ncols) ]
            self.sapx.append(x)
            # y = [ sampley.cell(i,j).value for j in range(sampley.ncols) ]
            for j in range(sampley.ncols):
                y = [ 0, 0, 0, 0, 0 ]
                y[int(sampley.cell(i,j).value)]=1
                self.sapy.append(y)
        self.in_features=samplex.ncols
        self.out_features=sampley.ncols

    def getTestData(self,path,testX,testY):
        data = xlrd.open_workbook(path)
        samplex = data.sheet_by_name(testX)
        sampley = data.sheet_by_name(testY)
        self.tesx = []
        self.tesy = []
        for i in range(1,samplex.nrows):
            x = [ samplex.cell(i,j).value for j in range(samplex.ncols) ]
            self.tesx.append(x)
            # y = [ sampley.cell(i,j).value for j in range(sampley.ncols) ]
            for j in range(sampley.ncols):
                y = [ 0, 0, 0, 0, 0 ]
                y[int(sampley.cell(i,j).value)]=1
                self.tesy.append(y)


if __name__ == '__main__':

    print('\nCollecting experience...')
   
    file = 'trainning_Datas/TE1.xlsx'
    s = samples(file,'iris_x','iris_y')
    # s = samples(file,'train_x','train_y')
    x = s.sapx
    y = s.sapy
    train = training(x,y,100,5)
    train.lossTraining()
    train.figures()
    train.save()


    s.getTestData(file,'irtest_x','irtest_y')
    # # s.getTestData(file,'test_x','test_y')
    tx = s.tesx
    ty = s.tesy
    train.testNet(tx,ty)

    # print("\n***************** 调取网络测试 ******************* ")
    # net2 = torch.load('net.pkl')
    # tx = torch.tensor(tx).float()
    # out = net2(tx).data
    # for k in range(len(out)):
    #     print(k," -测试：",ty[k],"  -预测：",out[k])
